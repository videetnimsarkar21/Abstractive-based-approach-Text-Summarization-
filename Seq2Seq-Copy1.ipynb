{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"news_summary_more.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "MAX_INPUT_SEQ_LENGTH = 500\n",
    "MAX_TARGET_SEQ_LENGTH = 50\n",
    "MAX_INPUT_VOCAB_SIZE = 5000\n",
    "MAX_TARGET_VOCAB_SIZE = 2000\n",
    "\n",
    "\n",
    "def fit_text(X, Y, input_seq_max_length=None, target_seq_max_length=None):\n",
    "    if input_seq_max_length is None:\n",
    "        input_seq_max_length = MAX_INPUT_SEQ_LENGTH\n",
    "    if target_seq_max_length is None:\n",
    "        target_seq_max_length = MAX_TARGET_SEQ_LENGTH\n",
    "    input_counter = Counter()\n",
    "    target_counter = Counter()\n",
    "    max_input_seq_length = 0\n",
    "    max_target_seq_length = 0\n",
    "\n",
    "    for line in X:\n",
    "        text = [word.lower() for word in line.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > input_seq_max_length:\n",
    "            text = text[0:input_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            input_counter[word] += 1\n",
    "        max_input_seq_length = max(max_input_seq_length, seq_length)\n",
    "\n",
    "    for line in Y:\n",
    "        line2 = 'START ' + line.lower() + ' END'\n",
    "        text = [word for word in line2.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > target_seq_max_length:\n",
    "            text = text[0:target_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            target_counter[word] += 1\n",
    "            max_target_seq_length = max(max_target_seq_length, seq_length)\n",
    "\n",
    "    input_word2idx = dict()\n",
    "    for idx, word in enumerate(input_counter.most_common(MAX_INPUT_VOCAB_SIZE)):\n",
    "        input_word2idx[word[0]] = idx + 2\n",
    "    input_word2idx['PAD'] = 0\n",
    "    input_word2idx['UNK'] = 1\n",
    "    input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
    "\n",
    "    target_word2idx = dict()\n",
    "    for idx, word in enumerate(target_counter.most_common(MAX_TARGET_VOCAB_SIZE)):\n",
    "        target_word2idx[word[0]] = idx + 1\n",
    "    target_word2idx['UNK'] = 0\n",
    "\n",
    "    target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "    \n",
    "    num_input_tokens = len(input_word2idx)\n",
    "    num_target_tokens = len(target_word2idx)\n",
    "\n",
    "    config = dict()\n",
    "    config['input_word2idx'] = input_word2idx\n",
    "    config['input_idx2word'] = input_idx2word\n",
    "    config['target_word2idx'] = target_word2idx\n",
    "    config['target_idx2word'] = target_idx2word\n",
    "    config['num_input_tokens'] = num_input_tokens\n",
    "    config['num_target_tokens'] = num_target_tokens\n",
    "    config['max_input_seq_length'] = max_input_seq_length\n",
    "    config['max_target_seq_length'] = max_target_seq_length\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = fit_text(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqSummarizer(object):\n",
    "\n",
    "    model_name = 'seq2seq'\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.num_input_tokens = config['num_input_tokens']\n",
    "        self.max_input_seq_length = config['max_input_seq_length']\n",
    "        self.num_target_tokens = config['num_target_tokens']\n",
    "        self.max_target_seq_length = config['max_target_seq_length']\n",
    "        self.input_word2idx = config['input_word2idx']\n",
    "        self.input_idx2word = config['input_idx2word']\n",
    "        self.target_word2idx = config['target_word2idx']\n",
    "        self.target_idx2word = config['target_idx2word']\n",
    "        self.config = config\n",
    "\n",
    "        self.version = 0\n",
    "        if 'version' in config:\n",
    "            self.version = config['version']\n",
    "\n",
    "        encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "        encoder_embedding = Embedding(input_dim=self.num_input_tokens, output_dim=HIDDEN_UNITS,\n",
    "                                      input_length=self.max_input_seq_length, name='encoder_embedding')\n",
    "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_embedding(encoder_inputs))\n",
    "        encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None, self.num_target_tokens), name='decoder_inputs')\n",
    "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
    "        decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
    "                                                                         initial_state=encoder_states)\n",
    "        decoder_dense = Dense(units=self.num_target_tokens, activation='softmax', name='decoder_dense')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    def load_weights(self, weight_file_path):\n",
    "        if os.path.exists(weight_file_path):\n",
    "            self.model.load_weights(weight_file_path)\n",
    "\n",
    "    def transform_input_text(self, texts):\n",
    "        temp = []\n",
    "        for line in texts:\n",
    "            x = []\n",
    "            for word in line.lower().split(' '):\n",
    "                wid = 1\n",
    "                if word in self.input_word2idx:\n",
    "                    wid = self.input_word2idx[word]\n",
    "                x.append(wid)\n",
    "                if len(x) >= self.max_input_seq_length:\n",
    "                    break\n",
    "            temp.append(x)\n",
    "        temp = pad_sequences(temp, maxlen=self.max_input_seq_length)\n",
    "\n",
    "        print(temp.shape)\n",
    "        return temp\n",
    "\n",
    "    def transform_target_encoding(self, texts):\n",
    "        temp = []\n",
    "        for line in texts:\n",
    "            x = []\n",
    "            line2 = 'START ' + line.lower() + ' END'\n",
    "            for word in line2.split(' '):\n",
    "                x.append(word)\n",
    "                if len(x) >= self.max_target_seq_length:\n",
    "                    break\n",
    "            temp.append(x)\n",
    "\n",
    "        temp = np.array(temp)\n",
    "        print(temp.shape)\n",
    "        return temp\n",
    "\n",
    "    def generate_batch(self, x_samples, y_samples, batch_size):\n",
    "        num_batches = len(x_samples) // batch_size\n",
    "        while True:\n",
    "            for batchIdx in range(0, num_batches):\n",
    "                start = batchIdx * batch_size\n",
    "                end = (batchIdx + 1) * batch_size\n",
    "                encoder_input_data_batch = pad_sequences(x_samples[start:end], self.max_input_seq_length)\n",
    "                decoder_target_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, self.num_target_tokens))\n",
    "                decoder_input_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, self.num_target_tokens))\n",
    "                for lineIdx, target_words in enumerate(y_samples[start:end]):\n",
    "                    for idx, w in enumerate(target_words):\n",
    "                        w2idx = 0  # default [UNK]\n",
    "                        if w in self.target_word2idx:\n",
    "                            w2idx = self.target_word2idx[w]\n",
    "                        if w2idx != 0:\n",
    "                            decoder_input_data_batch[lineIdx, idx, w2idx] = 1\n",
    "                            if idx > 0:\n",
    "                                decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
    "                yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch\n",
    "\n",
    "    @staticmethod\n",
    "    def get_weight_file_path(model_dir_path):\n",
    "        return '-weights.h5'\n",
    "\n",
    "    @staticmethod\n",
    "    def get_config_file_path(model_dir_path):\n",
    "        return '-config.npy'\n",
    "\n",
    "    @staticmethod\n",
    "    def get_architecture_file_path(model_dir_path):\n",
    "        return '-architecture.json'\n",
    "\n",
    "    def fit(self, Xtrain, Ytrain, Xtest, Ytest, epochs=None, batch_size=None, model_dir_path=None):\n",
    "        if epochs is None:\n",
    "            epochs = DEFAULT_EPOCHS\n",
    "        if model_dir_path is None:\n",
    "            model_dir_path = './models'\n",
    "        if batch_size is None:\n",
    "            batch_size = DEFAULT_BATCH_SIZE\n",
    "\n",
    "        self.version += 1\n",
    "        self.config['version'] = self.version\n",
    "        config_file_path = Seq2SeqSummarizer.get_config_file_path(model_dir_path)\n",
    "        weight_file_path = Seq2SeqSummarizer.get_weight_file_path(model_dir_path)\n",
    "        checkpoint = ModelCheckpoint(weight_file_path)\n",
    "        np.save(config_file_path, self.config)\n",
    "        architecture_file_path = Seq2SeqSummarizer.get_architecture_file_path(model_dir_path)\n",
    "        open(architecture_file_path, 'w').write(self.model.to_json())\n",
    "\n",
    "        Ytrain = self.transform_target_encoding(Ytrain)\n",
    "        Ytest = self.transform_target_encoding(Ytest)\n",
    "\n",
    "        Xtrain = self.transform_input_text(Xtrain)\n",
    "        Xtest = self.transform_input_text(Xtest)\n",
    "\n",
    "        train_gen = self.generate_batch(Xtrain, Ytrain, batch_size)\n",
    "        test_gen = self.generate_batch(Xtest, Ytest, batch_size)\n",
    "\n",
    "        train_num_batches = len(Xtrain) // batch_size\n",
    "        test_num_batches = len(Xtest) // batch_size\n",
    "\n",
    "        history = self.model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
    "                                           epochs=epochs,\n",
    "                                           verbose=VERBOSE, validation_data=test_gen, validation_steps=test_num_batches,\n",
    "                                           callbacks=[checkpoint])\n",
    "        self.model.save_weights(weight_file_path)\n",
    "        return history\n",
    "\n",
    "    def summarize(self, input_text):\n",
    "        input_seq = []\n",
    "        input_wids = []\n",
    "        for word in input_text.lower().split(' '):\n",
    "            idx = 1  # default [UNK]\n",
    "            if word in self.input_word2idx:\n",
    "                idx = self.input_word2idx[word]\n",
    "            input_wids.append(idx)\n",
    "        input_seq.append(input_wids)\n",
    "        input_seq = pad_sequences(input_seq, self.max_input_seq_length)\n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "        target_seq = np.zeros((1, 1, self.num_target_tokens))\n",
    "        target_seq[0, 0, self.target_word2idx['START']] = 1\n",
    "        target_text = ''\n",
    "        target_text_len = 0\n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "            sample_word = self.target_idx2word[sample_token_idx]\n",
    "            target_text_len += 1\n",
    "\n",
    "            if sample_word != 'START' and sample_word != 'END':\n",
    "                target_text += ' ' + sample_word\n",
    "\n",
    "            if sample_word == 'END' or target_text_len >= self.max_target_seq_length:\n",
    "                terminated = True\n",
    "\n",
    "            target_seq = np.zeros((1, 1, self.num_target_tokens))\n",
    "            target_seq[0, 0, sample_token_idx] = 1\n",
    "\n",
    "            states_value = [h, c]\n",
    "        return target_text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Videet\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_UNITS = 100\n",
    "DEFAULT_BATCH_SIZE = 64\n",
    "VERBOSE = 1\n",
    "DEFAULT_EPOCHS = 10\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, Input\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "summarizer = Seq2SeqSummarizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78720,)\n",
      "(19681,)\n",
      "(78720, 92)\n",
      "(19681, 92)\n",
      "Epoch 1/150\n",
      "1230/1230 [==============================] - 657s 534ms/step - loss: 0.9456 - acc: 0.1797 - val_loss: 1.6011 - val_acc: 0.1050\n",
      "Epoch 2/150\n",
      "1230/1230 [==============================] - 676s 550ms/step - loss: 0.9415 - acc: 0.1804 - val_loss: 1.6058 - val_acc: 0.1048\n",
      "Epoch 3/150\n",
      "1230/1230 [==============================] - 701s 570ms/step - loss: 0.9379 - acc: 0.1809 - val_loss: 1.6126 - val_acc: 0.1039\n",
      "Epoch 4/150\n",
      "1230/1230 [==============================] - 717s 583ms/step - loss: 0.9345 - acc: 0.1816 - val_loss: 1.6199 - val_acc: 0.1033\n",
      "Epoch 5/150\n",
      "1230/1230 [==============================] - 443s 360ms/step - loss: 0.9307 - acc: 0.1821 - val_loss: 1.6260 - val_acc: 0.1033\n",
      "Epoch 6/150\n",
      "1230/1230 [==============================] - 436s 355ms/step - loss: 0.9273 - acc: 0.1826 - val_loss: 1.6314 - val_acc: 0.1026\n",
      "Epoch 7/150\n",
      "1230/1230 [==============================] - 442s 360ms/step - loss: 0.9244 - acc: 0.1833 - val_loss: 1.6361 - val_acc: 0.1027\n",
      "Epoch 8/150\n",
      "1230/1230 [==============================] - 443s 360ms/step - loss: 0.9213 - acc: 0.1837 - val_loss: 1.6433 - val_acc: 0.1016\n",
      "Epoch 9/150\n",
      "1230/1230 [==============================] - 445s 362ms/step - loss: 0.9184 - acc: 0.1841 - val_loss: 1.6495 - val_acc: 0.1019\n",
      "Epoch 10/150\n",
      "1230/1230 [==============================] - 445s 362ms/step - loss: 0.9157 - acc: 0.1846 - val_loss: 1.6512 - val_acc: 0.1019\n",
      "Epoch 11/150\n",
      "1230/1230 [==============================] - 445s 362ms/step - loss: 0.9126 - acc: 0.1852 - val_loss: 1.6563 - val_acc: 0.1025\n",
      "Epoch 12/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.9099 - acc: 0.1856 - val_loss: 1.6602 - val_acc: 0.1010\n",
      "Epoch 13/150\n",
      "1230/1230 [==============================] - 445s 362ms/step - loss: 0.9074 - acc: 0.1861 - val_loss: 1.6666 - val_acc: 0.1009\n",
      "Epoch 14/150\n",
      "1230/1230 [==============================] - 443s 361ms/step - loss: 0.9049 - acc: 0.1865 - val_loss: 1.6701 - val_acc: 0.1013\n",
      "Epoch 15/150\n",
      "1230/1230 [==============================] - 445s 362ms/step - loss: 0.9022 - acc: 0.1870 - val_loss: 1.6742 - val_acc: 0.1010\n",
      "Epoch 16/150\n",
      "1230/1230 [==============================] - 444s 361ms/step - loss: 0.8998 - acc: 0.1874 - val_loss: 1.6777 - val_acc: 0.1006\n",
      "Epoch 17/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.8974 - acc: 0.1878 - val_loss: 1.6817 - val_acc: 0.1011\n",
      "Epoch 18/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.8950 - acc: 0.1881 - val_loss: 1.6867 - val_acc: 0.1006\n",
      "Epoch 19/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.8929 - acc: 0.1888 - val_loss: 1.6894 - val_acc: 0.1001\n",
      "Epoch 20/150\n",
      "1230/1230 [==============================] - 445s 362ms/step - loss: 0.8908 - acc: 0.1891 - val_loss: 1.6899 - val_acc: 0.1001\n",
      "Epoch 21/150\n",
      "1230/1230 [==============================] - 445s 362ms/step - loss: 0.8881 - acc: 0.1896 - val_loss: 1.6950 - val_acc: 0.1001\n",
      "Epoch 22/150\n",
      "1230/1230 [==============================] - 444s 361ms/step - loss: 0.8863 - acc: 0.1898 - val_loss: 1.7001 - val_acc: 0.0997\n",
      "Epoch 23/150\n",
      "1230/1230 [==============================] - 446s 362ms/step - loss: 0.8839 - acc: 0.1904 - val_loss: 1.7048 - val_acc: 0.0997\n",
      "Epoch 24/150\n",
      "1230/1230 [==============================] - 446s 362ms/step - loss: 0.8817 - acc: 0.1909 - val_loss: 1.7053 - val_acc: 0.0998\n",
      "Epoch 25/150\n",
      "1230/1230 [==============================] - 448s 364ms/step - loss: 0.8791 - acc: 0.1913 - val_loss: 1.7089 - val_acc: 0.0993\n",
      "Epoch 26/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.8773 - acc: 0.1916 - val_loss: 1.7134 - val_acc: 0.0993\n",
      "Epoch 27/150\n",
      "1230/1230 [==============================] - 447s 363ms/step - loss: 0.8747 - acc: 0.1920 - val_loss: 1.7163 - val_acc: 0.0994\n",
      "Epoch 28/150\n",
      "1230/1230 [==============================] - 447s 363ms/step - loss: 0.8732 - acc: 0.1922 - val_loss: 1.7196 - val_acc: 0.0997\n",
      "Epoch 29/150\n",
      "1230/1230 [==============================] - 448s 364ms/step - loss: 0.8706 - acc: 0.1926 - val_loss: 1.7246 - val_acc: 0.0990\n",
      "Epoch 30/150\n",
      "1230/1230 [==============================] - 448s 364ms/step - loss: 0.8688 - acc: 0.1930 - val_loss: 1.7274 - val_acc: 0.0987\n",
      "Epoch 31/150\n",
      "1230/1230 [==============================] - 449s 365ms/step - loss: 0.8670 - acc: 0.1933 - val_loss: 1.7292 - val_acc: 0.0983\n",
      "Epoch 32/150\n",
      "1230/1230 [==============================] - 447s 364ms/step - loss: 0.8651 - acc: 0.1939 - val_loss: 1.7305 - val_acc: 0.0983\n",
      "Epoch 33/150\n",
      "1230/1230 [==============================] - 448s 365ms/step - loss: 0.8631 - acc: 0.1940 - val_loss: 1.7350 - val_acc: 0.0988\n",
      "Epoch 34/150\n",
      "1230/1230 [==============================] - 448s 365ms/step - loss: 0.8610 - acc: 0.1946 - val_loss: 1.7382 - val_acc: 0.0977\n",
      "Epoch 35/150\n",
      "1230/1230 [==============================] - 448s 364ms/step - loss: 0.8593 - acc: 0.1947 - val_loss: 1.7427 - val_acc: 0.0981\n",
      "Epoch 36/150\n",
      "1230/1230 [==============================] - 448s 364ms/step - loss: 0.8573 - acc: 0.1952 - val_loss: 1.7432 - val_acc: 0.0984\n",
      "Epoch 37/150\n",
      "1230/1230 [==============================] - 447s 364ms/step - loss: 0.8556 - acc: 0.1955 - val_loss: 1.7481 - val_acc: 0.0978\n",
      "Epoch 38/150\n",
      "1230/1230 [==============================] - 447s 364ms/step - loss: 0.8538 - acc: 0.1956 - val_loss: 1.7508 - val_acc: 0.0974\n",
      "Epoch 39/150\n",
      "1230/1230 [==============================] - 448s 364ms/step - loss: 0.8523 - acc: 0.1960 - val_loss: 1.7530 - val_acc: 0.0979\n",
      "Epoch 40/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.8502 - acc: 0.1964 - val_loss: 1.7553 - val_acc: 0.0972\n",
      "Epoch 41/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.8493 - acc: 0.1966 - val_loss: 1.7574 - val_acc: 0.0973\n",
      "Epoch 42/150\n",
      "1230/1230 [==============================] - 446s 363ms/step - loss: 0.8471 - acc: 0.1971 - val_loss: 1.7616 - val_acc: 0.0974\n",
      "Epoch 43/150\n",
      " 611/1230 [=============>................] - ETA: 3:29 - loss: 0.8484 - acc: 0.1970"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5e65c6a552c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-dc2240b18e59>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, Xtrain, Ytrain, Xtest, Ytest, epochs, batch_size, model_dir_path)\u001b[0m\n\u001b[0;32m    146\u001b[0m                                            \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                                            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_num_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                                            callbacks=[checkpoint])\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = summarizer.fit(Xtrain, Ytrain, Xtest, Ytest, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Article:  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "Generated Headline:  infosys to start stock stock worth less than a year\n",
      "Original Headline:  upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "1\n",
      "Article:  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "Generated Headline:  govt to free free food from dad for man for unveiled\n",
      "Original Headline:  Delhi techie wins free food from Swiggy for one year on CRED\n",
      "2\n",
      "Article:  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "Generated Headline:  new zealand player win a day bowler to ipl final\n",
      "Original Headline:  New Zealand end Rohit Sharma-led India's 12-match winning streak\n",
      "3\n",
      "Article:  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
      "Generated Headline:  how to have you have been a month for people\n",
      "Original Headline:  Aegon life iTerm insurance plan helps customers save tax\n",
      "4\n",
      "Article:  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman. But in this case, we need to reserve our judgment,\" she added. Hirani has been accused by an assistant who worked in 'Sanju'.\n",
      "Generated Headline:  don't give people to sexual harassment in sonam kapoor\n",
      "Original Headline:  Have known Hirani for yrs, what if MeToo claims are not true: Sonam\n",
      "5\n",
      "Article:  Pakistani singer Rahat Fateh Ali Khan has denied receiving any notice from the Enforcement Directorate over allegedly smuggling foreign currency out of India. \"It would have been better if the authorities would have served the notice first if any and then publicised this,\" reads a press release issued on behalf of Rahat. The statement further called the allegation \"bizarre\".\n",
      "Generated Headline:  pak actress denies being hit by police call for tax class\n",
      "Original Headline:  Rahat Fateh Ali Khan denies getting notice for smuggling currency\n",
      "6\n",
      "Article:  India recorded their lowest ODI total in New Zealand after getting all out for 92 runs in 30.5 overs in the fourth ODI at Hamilton on Thursday. Seven of India's batsmen were dismissed for single-digit scores, while their number ten batsman Yuzvendra Chahal top-scored with 18*(37). India's previous lowest ODI total in New Zealand was 108.\n",
      "Generated Headline:  india lose out in new odi odi series in 2 years after 1st time\n",
      "Original Headline:  India get all out for 92, their lowest ODI total in New Zealand\n",
      "7\n",
      "Article:  Weeks after ex-CBI Director Alok Verma told the Department of Personnel and Training to consider him retired, the Home Ministry asked him to join work on the last day of his fixed tenure as Director on Thursday. The ministry directed him to immediately join as DG, Fire Services, the post he was transferred to after his removal as CBI chief.\n",
      "Generated Headline:  govt asks people to know about his army chief\n",
      "Original Headline:  Govt directs Alok Verma to join work 1 day before his retirement\n",
      "8\n",
      "Article:  Andhra Pradesh CM N Chandrababu Naidu has said, \"When I met then US President Bill Clinton, I addressed him as Mr Clinton, not as 'sir'. (PM Narendra) Modi is my junior in politics...I addressed him as sir 10 times.\" \"I did this...to satisfy his ego in the hope that he will do justice to the state,\" he added.\n",
      "Generated Headline:  i was pm modi, i get a dog in andhra cm kejriwal makes\n",
      "Original Headline:  Called PM Modi 'sir' 10 times to satisfy his ego: Andhra CM\n",
      "9\n",
      "Article:  Congress candidate Shafia Zubair won the Ramgarh Assembly seat in Rajasthan, by defeating BJP's Sukhwant Singh with a margin of 12,228 votes in the bypoll. With this victory, Congress has taken its total to 100 seats in the 200-member assembly. The election to the Ramgarh seat was delayed due to the death of sitting MLA and BSP candidate Laxman Singh.\n",
      "Generated Headline:  cong wins rajasthan polls first-ever for ec\n",
      "Original Headline:  Cong wins Ramgarh bypoll in Rajasthan, takes total to 100 seats\n",
      "10\n",
      "Article:  Two minor cousins in Uttar Pradesh's Gorakhpur were allegedly repeatedly burnt with tongs and forced to eat human excreta by their family for being friends with two boys from the same school. The cousins revealed their ordeal to the police and Child Welfare Committee after being brought back to Gorakhpur from Nepal, where they had fled to escape the torture.\n",
      "Generated Headline:  up man who was the indian woman with her to find on her\n",
      "Original Headline:  UP cousins fed human excreta for friendship with boys\n",
      "11\n",
      "Article:  Isha Ghosh, an 81-year-old member of Bharat Scouts and Guides (BSG), has been imparting physical and mental training to schoolchildren in Jharkhand for several decades. Chaibasa-based Ghosh reportedly walks seven kilometres daily and spends eight hours conducting physical training, apart from climbing and yoga sessions. She says, \"One should do something for society till one's last breath.\"\n",
      "Generated Headline:  andhra pradesh village body announces â¹1 of his name\n",
      "Original Headline:  81-yr-old woman conducts physical training in J'khand schools\n",
      "12\n",
      "Article:  Urging saints and seers at the Kumbh Mela to quit smoking, Yoga guru Ramdev said, \"We follow Ram and Krishna who never smoked in their life then why should we?\" Making them take a pledge to quit tobacco, he collected chillum (clay pipe) from several sadhus. He said he will deposit the chillums for display at a museum he'll build.\n",
      "Generated Headline:  why should do you at the temple in uk\n",
      "Original Headline:  Ram, Krishna didn't smoke, why should we: Ramdev to sadhus at Kumbh\n",
      "13\n",
      "Article:  Former stripper and regional sales director of a pharmaceutical company, Sunrise Lee, gave a doctor a lap dance in a nightclub to persuade him to prescribe an addictive fentanyl spray in 2012, the company's sales representative told a US court. She said she saw Lee \"sitting on [doctor's] lap, kind of bouncing around.\" Lee has been accused of bribing doctors.\n",
      "Generated Headline:  what is the the sex sues his party\n",
      "Original Headline:  Pharma exec gave doctor a lap dance to sell medicine in US: Witness\n",
      "14\n",
      "Article:  Reliance Industries' Chairman Mukesh Ambani's daughter Isha Ambani, who got married last month, said she only cried at her 'bidaai' because she felt peer pressure as everyone was crying, especially her parents. \"I was emotional too but everyone around me would cry all the time,\" she added. \"It was a very emotional affair for everyone in my family,\" said Isha.\n",
      "Generated Headline:  i was at his first female director after his ambani\n",
      "Original Headline:   I only cried at my 'bidaai' as I felt peer pressure: Isha Ambani\n",
      "15\n",
      "Article:  Louis Vuitton owner LVMH, which makes high-end beverages like MoÃ«t & Chandon champagne and Hennessy cognac, said it's stockpiling four months' worth of wine and spirits in UK in preparation for Brexit. \"We're ready for worst case scenario if there are difficulties with deliveries,\" the French luxury giant said. The UK is scheduled to leave the EU on March 29.\n",
      "Generated Headline:  uk court case of 10 months of man for being a year\n",
      "Original Headline:  Louis Vuitton owner to stockpile 4 months of wine, spirits in UK\n",
      "16\n",
      "Article:  Filmmaker Karan Johar and actress Tabu turned showstoppers for Gaurav Gupta on the opening night of LakmÃ© Fashion Week Summer/ Resort 2019. While Johar wore a red sequinned jacket with black pants, Tabu walked the ramp in a grey embellished gown. The fashion show, which began on January 29, will continue till February 3.\n",
      "Generated Headline:  karan johar made its first time in 2 years of ipl 2018\n",
      "Original Headline:  Karan Johar, Tabu turn showstoppers on opening night of LFW\n",
      "17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:  In a jibe at Congress President Rahul Gandhi, PM Narendra Modi on Wednesday said those on \"bail will have to go to jail.\" PM Modi added, \"He is out on bail and his associates too are facing charges...I know they will be convicted one day.\" The PM claimed he'd waged a war on corruption because he's from a common household. \n",
      "Generated Headline:  time to be pm modi should be held in rahul on pm modi\n",
      "Original Headline:  Those on bail will go to jail: PM Modi takes jibe at Rahul\n",
      "18\n",
      "Article:  Days after he threatened to step down from his post if Congress MLAs continue \"crossing the line,\" Karnataka Chief Minister HD Kumaraswamy accused them of taking potshots and asked, \"How many more days can I tolerate such stuff?\" Kumaraswamy, who made the statements after a Congress MLA demanded that Siddaramaiah be made CM again, said, \"Power is ephemeral.\"\n",
      "Generated Headline:  you are the right to karnataka bjp mla on k'taka govt\n",
      "Original Headline:  How long can I tolerate Congress leaders' potshots: K'taka CM\n",
      "19\n",
      "Article:  Union Minister Dharmendra Pradhan on Wednesday claimed the illegal mining mafia in Odisha operates under the control of CM Naveen Patnaik and state Congress chief Niranjan Patnaik. He added, \"The time has come for the people of Odisha to put a full stop to their activities...The time has come for us to ask for an explanation from this corrupt government.\"\n",
      "Generated Headline:  odisha cm cow illegal in a second\n",
      "Original Headline:  Odisha CM Patnaik controls mining mafia: Union Minister\n",
      "20\n",
      "Article:  Claiming there is a dearth of ideas among opposition parties, Prime Minister Narendra Modi on Wednesday said, \"The opposition talks only about Modi the whole day, I suspect they even dream about me.\" PM Modi, who was addressing the New India Youth Conclave inâ Surat, added that the opposition parties have only one agenda which is \"Modi\". \n",
      "Generated Headline:  i don't want to be more for us: bjp leader on death row\n",
      "Original Headline:  I think the opposition even dreams about me: PM Modi\n",
      "21\n",
      "Article:  The Indian Space Research Organisation on Wednesday unveiled Human Space Flight Centre in Bengaluru for its â¹10,000-crore manned space mission 'Gaganyaan' scheduled for 2021. ISRO said the centre will be responsible for development of engineering systems for crew survival in space and crew selection and training. It'll also pursue activities for sustained human space flight missions, ISRO added.\n",
      "Generated Headline:  isro unveils its launch of road training\n",
      "Original Headline:  ISRO unveils Bengaluru centre for manned space mission \n",
      "22\n",
      "Article:  At least 12 people have been killed and 170 others have been injured in Saudi Arabia this week due to flooding from heavy rain. The emergency services rescued 271 people from the flooded areas, more than half of them in Tabuk. Heavy rains hit mainly western and northwestern parts of Saudi Arabia, near its border with Jordan.\n",
      "Generated Headline:  50 killed, 100 injured in saudi for crash crash\n",
      "Original Headline:  12 killed, 170 injured in Saudi Arabia floods\n",
      "23\n",
      "Article:  Reliance Industries' Chairman Mukesh Ambani's daughter Isha Ambani has featured on the cover of the February edition of Vogue India. She's dressed in a white shirt dress and black ruffled skirt by Australian designer Toni Maticevski, while accessorising her look with a Misho ring. In the cover story on her, Isha has spoken about her work and life after marriage.\n",
      " \n",
      "Generated Headline:  mukesh ambani on whatsapp deal with highest show cbi\n",
      "Original Headline:  Isha Ambani features on February cover of Vogue magazine\n",
      "24\n",
      "Article:  Indian Oil Corporation on Wednesday said it's looking for an annual deal to buy US crude as it seeks to broaden oil purchasing options. This comes amid uncertainties over Iran imports. The US had in November granted a six-month waiver to India from sanctions against Iran and restricted the country's monthly intake of Iranian oil to 3,00,000 barrels per day.\n",
      "\n",
      "\n",
      "Generated Headline:  trump to buy ready for air india pay reports for killing\n",
      "Original Headline:  Indian Oil looking for annual deal to buy crude from US\n",
      "25\n",
      "Article:  Former Windies fast bowler Curtly Ambrose dismissed seven Australian batsmen within a span of 32 balls giving away just one run, in a Test match on January 30, 1993. Ambrose's spell helped his team bowl out Australia for 119 in the first innings, after being 85 for 2 at one point. Ambrose ended with first-innings figures of 18-9-25-7.\n",
      "Generated Headline:  7 years of the ball of ipl 2018 as no one muslim man out of me: kohli\n",
      "Original Headline:  Pacer once took 7 wickets for just 1 run in 32 balls in a Test\n",
      "26\n",
      "Article:  A London zoo is offering people to name a cockroach after their exes on Valentine's Day for Â£1.50 (nearly â¹140). \"For those that don't quite require revenge, there's another way to make you feel better about getting back at your ex,\" the zoo said in a statement. The names will appear on zoo's 'roach board' on February 14. \n",
      "Generated Headline:  uk for mumbai people to give a to work as a day\n",
      "Original Headline:  UK zoo offers people to name cockroach after their ex on Valentine's\n",
      "27\n",
      "Article:  Stand-in captain Rohit Sharma has become the 14th Indian cricketer to play 200 ODIs, achieving the feat after taking the field against New Zealand in fourth ODI at Hamilton on Thursday. The 31-year-old had made his ODI debut on June 23, 2007, against Ireland in Belfast. Rohit scored 7,799 runs in his first 199 ODIs at an average of 48.14.\n",
      "Generated Headline:  rohit sharma to play indian cricket team captain\n",
      "Original Headline:  Rohit Sharma becomes 14th Indian cricketer to play 200 ODIs\n",
      "28\n",
      "Article:  Batsman Shubman Gill has become the 227th cricketer to represent India in ODI cricket, achieving the feat against New Zealand in the fourth ODI at Hamilton on Thursday. The 19-year-old received his maiden ODI cap from former captain MS Dhoni. Notably, Shubman was named Player of the Under-19 World Cup in New Zealand last year.\n",
      "Generated Headline:  who is the fastest odi cricket team in india\n",
      "Original Headline:  19-year-old Shubman Gill becomes India's 227th ODI cricketer\n",
      "29\n",
      "Article:  Investigators searching for a lost plane carrying Argentine forward Emiliano Sala found two seat cushions on French coast that \"likely\" belonged to the aircraft. The investigators said they'll now launch an underwater seabed search for aircraft wreckage. The Cardiff City footballer was travelling from France's Nantes to Wales' Cardiff when his plane disappeared over English Channel on January 21.\n",
      "Generated Headline:  3 years of plane stolen from mumbai station\n",
      "Original Headline:  2 seat cushions from 'missing plane carrying footballer' found\n",
      "30\n",
      "Article:  Italian third division football side Lucchese's head coach Giancarlo Favarin has been banned for five months for headbutting Alessandria's assistant coach Gaetano Mancino during a brawl following the teams' 2-2 draw on Sunday. Mancino was caught off-balance and knocked to the ground after the headbutt. Earlier in the match, Favarin had told his own player to break an opponent's legs.\n",
      "Generated Headline:  coach player banned for 13 years over illegal wins coach\n",
      "Original Headline:  Italian coach knocks rival down with headbutt, banned for 5 months\n",
      "31\n",
      "Article:  Cyclists taking part in National Track Cycling Championship in Jaipur opted to sleep on the floor inside the stadium instead of hotels over expensive cycles. The organisers had booked hotels but they didn't have the provision for cyclists to keep their bikes inside. A national gold medallist said their cycles cost between â¹5-9 lakh and once damaged, they become non-repairable. \n",
      "Generated Headline:  man who who are 10 yrs worth â¹1 lakh to buy cars\n",
      "Original Headline:  Cyclists sleep on stadium floor instead of hotel over costly cycles\n",
      "32\n",
      "Article:  Silvia Grecco, a 56-year-old Brazilian mother narrates her local football team Palmeiras' matches live to her 12-year-old blind and autistic son Nickollas from the stands. \"I describe details: this player is wearing short sleeves...colour of...football boots, hair colour...Everything I see and feel, I tell him, even when I need to curse the referee!\" Grecco said after a recent match.\n",
      "Generated Headline:  will mother to be shot in his family tweets user on her\n",
      "Original Headline:  Brazilian mother narrates football matches to blind son from stands\n",
      "33\n",
      "Article:  A TechCrunch report has claimed that Indiaâs largest bank SBI secured a passwordless server \"overnight\" on being alerted it allowed anyone to access phone numbers, bank balances, and transactions of millions of its customers. The Mumbai-based server was containing two months of data from SBI Quick, an SMS and call-based system used to request basic information about accounts, TechCrunch revealed.\n",
      "Generated Headline:  sbi data arrested in working on whatsapp that largest bank\n",
      "Original Headline:  SBI left account data of millions of users unprotected: Report\n",
      "34\n",
      "Article:  Rahul Gandhi has replied to Goa CM Manohar Parrikar's letter, which accused the Congress President of using his \"visit to an ailing man for political gains\". \"He's under immense pressure from the PM after our meeting and needs to demonstrate his loyalty by attacking me,\" Gandhi wrote in his letter. Parrikar had clarified he didn't discuss Rafale deal with Rahul.\n",
      "Generated Headline:  cong mla from cm to trolled for using his family with kohli\n",
      "Original Headline:  CM Parrikar under pressure from PM after our Goa meet: Rahul\n",
      "35\n",
      "Article:  Twenty-seven-year-old Mohammed Mahuwala was arrested in Indore on Wednesday for allegedly cheating e-commerce giant Amazon of nearly â¹30 lakh. Mahuwala was a member of a gang who ordered costly gadgets from Amazon. \"[They] used to get refund of the amount paid...by saying the parcel...was empty. In reality, these devices were taken out from parcel and sold...to local shopkeepers,\" said police.\n",
      "Generated Headline:  man who took 10 yrs for stealing worth of crore in apple\n",
      "Original Headline:  Man arrested for cheating Amazon of â¹30 lakh by taking refunds\n",
      "36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:  AgustaWestland chopper scam co-accused Rajiv Saxena was extradited to India from UAE on Wednesday. He had been evading the Enforcement Directorate's summons claiming he was suffering from leukaemia but had moved an anti-money laundering court for anticipatory bail in December, stating he had never been summoned at his Dubai address. Saxena's lawyers alleged he had been \"illegally extradited\". \n",
      "Generated Headline:  bcci ceo accused of pm in a year\n",
      "Original Headline:  AgustaWestland scam accused Rajiv Saxena extradited to India\n",
      "37\n",
      "Article:  Afghan President Ashraf Ghani has said the \"keys to war\" are in Pakistan's Islamabad, Quetta and Rawalpindi, accusing the country of providing safe havens to militants, including those belonging to the Taliban. Ghani added the \"key to peace was in Afghanistan\". His comments came amid the talks between the US and the Taliban to end the 17-year war in Afghanistan.\n",
      "Generated Headline:  pakistan can give a muslim each other indian prez\n",
      "Original Headline:  Pakistan holds 'keys to war': Afghanistan\n",
      "38\n",
      "Article:  A Singapore-based insurance agent has been jailed for two years and five months for threatening to harm his clients unless they paid him in bitcoins. The 36-year-old set up an email account, and signed the messages as 'Lord Voldemort', a fictional character from the Harry Potter series. Ye Lin Myint targeted about 33 people, including those who cancelled insurance policies.\n",
      "Generated Headline:  drone gets jailed for 1st to death for not a baby\n",
      "Original Headline:  Insurance agent 'Lord Voldemort' jailed for threatening clients\n",
      "39\n",
      "Article:  Gabrielle Reilly, a 22-year-old US woman, created earrings for her Apple AirPods and put it up for sale online for $20 (about â¹1,500). \"I absolutely refuse to lose them (AirPods)...So I made earrings,\" she explained. The earrings, which took her over an hour to make, debuted in a video on Twitter that has since garnered over three million views.\n",
      "Generated Headline:  man buys apple for selling children to buy on sale for 2018\n",
      "Original Headline:  Woman turns Apple AirPods into earrings to avoid losing them\n",
      "40\n",
      "Article:  Ex-ICICI Bank CEO Chanda Kochhar said she's \"utterly disappointed, hurt and shocked\" by the bank's decision to terminate her. Kochhar said she served ICICI for 34 years with utmost honesty and integrity and that ultimately truth will prevail. Adding that she hasn't been given a copy of the independent probe report, Kochhar said none of ICICI's credit decisions are unilateral\n",
      "Generated Headline:  i have accused of the indian in india: actress\n",
      "Original Headline:  Shocked, hurt by ICICI's decision, truth will prevail: Kochhar\n",
      "41\n",
      "Article:  Swedish multinational fast-fashion brand Hennes & Mauritz AB (H&M) has hired Christopher Wylie, the whistleblower who exposed Facebook's Cambridge Analytica data scandal. Wylieâs focus will be to help get better insights on customers, products and markets and support work on sustainable and ethical artificial intelligence, H&M spokesperson said. Wylie is a former employee of Cambridge Analytica.\n",
      "Generated Headline:  what is the biggest facebook shares used to virat\n",
      "Original Headline:  Fashion brand H&M hires Facebook data scandal whistleblower\n",
      "42\n",
      "Article:  Micro-blogging platform Twitter is testing a new feature on Android to put news on the top of a user's timeline. \"With this update, weâre making it easier for people to see news and stories their followers have been discussing,\" Product Manager Walter Gurzynski said. The feature comes alongside a prompt saying, \"Catch up on what's happened while you were away.\"\n",
      "Generated Headline:  twitter users on new feature to play using users\n",
      "Original Headline:  Twitter testing news-first timeline feature on Android\n",
      "43\n",
      "Article:  Samsung has started mass producing its one terabyte 'embedded Universal Flash Storage (eUFS) 2.1' technology for \"use in next-generation mobile applications\", which it claims is the industry's first such eUFS. The company added the new eUFS will let smartphones store 260 10-minute videos shot in 4K UHD format. It'll be sized the same as the previous 512GB version, Samsung said.\n",
      "Generated Headline:  samsung plans world's largest feature in india\n",
      "Original Headline:  Samsung builds world's first 1TB storage chip for smartphones \n",
      "44\n",
      "Article:  Prime Minister Narendra Modi on Wednesday said the people with 'negative mindset' are questioning him and his government for floating pro-poor schemes. He added negative mindset people are raising doubts about schemes such as building toilets and providing free gas connections to the poor. He further said that negative mentality laced with a vested interest still exists in the country.\n",
      "Generated Headline:  we are not in our people on our odi international\n",
      "Original Headline:  People with 'negative mindset' quizzing pro-poor schemes: PM\n",
      "45\n",
      "Article:  Union Minister Anantkumar Hegde took a dig at Congress President Rahul Gandhi by calling him a \"hybrid specimen\" who has no clue about religion. \"A father who's...Muslim, a mother who's...Christian and the son is supposed to be...Brahmin. How is that even possible?\" he said. He added such \"hybrid specimen\" cannot be found in any laboratory in the world.\n",
      "Generated Headline:  no rahul has to the my only from me: rahul on her name\n",
      "Original Headline:  Rahul is hybrid specimen, has no clue about religion: Hegde\n",
      "46\n",
      "Article:  Several parts of the US are set to experience record low temperatures as the polar vortex hit the Upper Midwest, with more than 200 million people expected to experience below-freezing temperatures this week. Temperatures throughout the Upper Midwest are expected to be at least 20-40â below zero. Government offices and schools have been closed in several areas.\n",
      "Generated Headline:  paris to pay tax on new zealand in kerala\n",
      "Original Headline:  Extreme cold to affect 200 million people as polar vortex hits US\n",
      "47\n",
      "Article:  The police on Wednesday registered cases against 13 persons, including a woman leader of Hindu Mahasabha, in Aligarh for firing at an effigy of Mahatma Gandhi with an air pistol. \"The incident took place in a house in Naurangabad locality of the city,\" Senior Superintendent of Police said. The video of the event went viral on social media, he added.\n",
      "Generated Headline:  4 arrested in afghanistan join bjp for us at iit\n",
      "Original Headline:  13 booked for firing air shots at Mahatma Gandhi's effigy\n",
      "48\n",
      "Article:  Railway police has rescued a woman travelling on a train in Chennai who got her leg stuck inside the commode of a toilet. After being caught inside the commode hole, she struggled to remove her leg and following failed attempts, she shouted for help, reports said. Railway police used a cutter to pry open the commode and freed her leg.\n",
      "Generated Headline:  railways to get stuck in train for 2 people dead woman\n",
      "Original Headline:  Railway police rescues woman with leg stuck in train toilet\n",
      "49\n",
      "Article:  The US on Tuesday began returning asylum seekers to Mexico, sending back a migrant from a Central American nation and called the move a \"response to the illegal migration crisis\" faced by it. Under its Migrant Protection Protocols policy, the US will return certain migrants who cross into the country illegally back to Mexico while their asylum requests are processed.\n",
      "Generated Headline:  us to back back military flights in canada\n",
      "Original Headline:  US begins sending back asylum seekers to Mexico\n"
     ]
    }
   ],
   "source": [
    "#summarizer.load_weights(weight_file_path=Seq2SeqSummarizer.get_weight_file_path(model_dir_path='seq2seq-weights.h5'))\n",
    "\n",
    "for i in range (50):\n",
    "    print(i)\n",
    "    x = X[i]\n",
    "    actual_headline = Y[i]\n",
    "    headline = summarizer.summarize(x)\n",
    "    print('Article: ', x)\n",
    "    print('Generated Headline: ', headline)\n",
    "    print('Original Headline: ', actual_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
