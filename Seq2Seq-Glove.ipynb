{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"news_summary_more.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['headlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "MAX_INPUT_SEQ_LENGTH = 500\n",
    "MAX_TARGET_SEQ_LENGTH = 50\n",
    "MAX_INPUT_VOCAB_SIZE = 5000\n",
    "MAX_TARGET_VOCAB_SIZE = 2000\n",
    "\n",
    "\n",
    "def fit_text(X, Y, input_seq_max_length=None, target_seq_max_length=None):\n",
    "    if input_seq_max_length is None:\n",
    "        input_seq_max_length = MAX_INPUT_SEQ_LENGTH\n",
    "    if target_seq_max_length is None:\n",
    "        target_seq_max_length = MAX_TARGET_SEQ_LENGTH\n",
    "    input_counter = Counter()\n",
    "    target_counter = Counter()\n",
    "    max_input_seq_length = 0\n",
    "    max_target_seq_length = 0\n",
    "\n",
    "    for line in X:\n",
    "        text = [word.lower() for word in line.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > input_seq_max_length:\n",
    "            text = text[0:input_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            input_counter[word] += 1\n",
    "        max_input_seq_length = max(max_input_seq_length, seq_length)\n",
    "\n",
    "    for line in Y:\n",
    "        line2 = 'START ' + line.lower() + ' END'\n",
    "        text = [word for word in line2.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > target_seq_max_length:\n",
    "            text = text[0:target_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            target_counter[word] += 1\n",
    "            max_target_seq_length = max(max_target_seq_length, seq_length)\n",
    "\n",
    "    input_word2idx = dict()\n",
    "    for idx, word in enumerate(input_counter.most_common(MAX_INPUT_VOCAB_SIZE)):\n",
    "        input_word2idx[word[0]] = idx + 2\n",
    "    input_word2idx['PAD'] = 0\n",
    "    input_word2idx['UNK'] = 1\n",
    "    input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
    "\n",
    "    target_word2idx = dict()\n",
    "    for idx, word in enumerate(target_counter.most_common(MAX_TARGET_VOCAB_SIZE)):\n",
    "        target_word2idx[word[0]] = idx + 1\n",
    "    target_word2idx['UNK'] = 0\n",
    "\n",
    "    target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "    \n",
    "    num_input_tokens = len(input_word2idx)\n",
    "    num_target_tokens = len(target_word2idx)\n",
    "\n",
    "    config = dict()\n",
    "    config['input_word2idx'] = input_word2idx\n",
    "    config['input_idx2word'] = input_idx2word\n",
    "    config['target_word2idx'] = target_word2idx\n",
    "    config['target_idx2word'] = target_idx2word\n",
    "    config['num_input_tokens'] = num_input_tokens\n",
    "    config['num_target_tokens'] = num_target_tokens\n",
    "    config['max_input_seq_length'] = max_input_seq_length\n",
    "    config['max_target_seq_length'] = max_target_seq_length\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = fit_text(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_EMBEDDING_SIZE = 100\n",
    "def load_glove(data_dir_path=None):\n",
    "    _word2em = {}\n",
    "    glove_model_path = \"glove.6B.100d.txt\"\n",
    "    file = open(glove_model_path, mode='rt', encoding='utf8')\n",
    "    for line in file:\n",
    "        words = line.strip().split()\n",
    "        word = words[0]\n",
    "        embeds = np.array(words[1:], dtype=np.float32)\n",
    "        _word2em[word] = embeds\n",
    "    file.close()\n",
    "    return _word2em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqGloVeSummarizer(object):\n",
    "\n",
    "    model_name = 'seq2seq-glove'\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.max_input_seq_length = config['max_input_seq_length']\n",
    "        self.num_target_tokens = config['num_target_tokens']\n",
    "        self.max_target_seq_length = config['max_target_seq_length']\n",
    "        self.target_word2idx = config['target_word2idx']\n",
    "        self.target_idx2word = config['target_idx2word']\n",
    "        self.version = 0\n",
    "        if 'version' in config:\n",
    "            self.version = config['version']\n",
    "\n",
    "        self.word2em = dict()\n",
    "        if 'unknown_emb' in config:\n",
    "            self.unknown_emb = config['unknown_emb']\n",
    "        else:\n",
    "            self.unknown_emb = np.random.rand(1, GLOVE_EMBEDDING_SIZE)\n",
    "            config['unknown_emb'] = self.unknown_emb\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
    "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
    "        encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "        decoder_inputs = Input(shape=(None, self.num_target_tokens), name='decoder_inputs')\n",
    "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
    "        decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
    "                                                                         initial_state=encoder_states)\n",
    "        decoder_dense = Dense(units=self.num_target_tokens, activation='softmax', name='decoder_dense')\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "        model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
    "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "        decoder_states = [state_h, state_c]\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "    def load_weights(self, weight_file_path):\n",
    "        if os.path.exists(weight_file_path):\n",
    "            self.model.load_weights(weight_file_path)\n",
    "\n",
    "    def load_glove(self, data_dir_path):\n",
    "        self.word2em = load_glove(data_dir_path)\n",
    "\n",
    "    def transform_input_text(self, texts):\n",
    "        temp = []\n",
    "        for line in texts:\n",
    "            x = np.zeros(shape=(self.max_input_seq_length, GLOVE_EMBEDDING_SIZE))\n",
    "            for idx, word in enumerate(line.lower().split(' ')):\n",
    "                if idx >= self.max_input_seq_length:\n",
    "                    break\n",
    "                emb = self.unknown_emb\n",
    "                if word in self.word2em:\n",
    "                    emb = self.word2em[word]\n",
    "                x[idx, :] = emb\n",
    "            temp.append(x)\n",
    "        temp = pad_sequences(temp, maxlen=self.max_input_seq_length)\n",
    "\n",
    "        print(temp.shape)\n",
    "        return temp\n",
    "\n",
    "    def transform_target_encoding(self, texts):\n",
    "        temp = []\n",
    "        for line in texts:\n",
    "            x = []\n",
    "            line2 = 'START ' + line.lower() + ' END'\n",
    "            for word in line2.split(' '):\n",
    "                x.append(word)\n",
    "                if len(x) >= self.max_target_seq_length:\n",
    "                    break\n",
    "            temp.append(x)\n",
    "\n",
    "        temp = np.array(temp)\n",
    "        print(temp.shape)\n",
    "        return temp\n",
    "\n",
    "    def generate_batch(self, x_samples, y_samples, batch_size):\n",
    "        num_batches = len(x_samples) // batch_size\n",
    "        while True:\n",
    "            for batchIdx in range(0, num_batches):\n",
    "                start = batchIdx * batch_size\n",
    "                end = (batchIdx + 1) * batch_size\n",
    "                encoder_input_data_batch = pad_sequences(x_samples[start:end], self.max_input_seq_length)\n",
    "                decoder_target_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, self.num_target_tokens))\n",
    "                decoder_input_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, self.num_target_tokens))\n",
    "                for lineIdx, target_words in enumerate(y_samples[start:end]):\n",
    "                    for idx, w in enumerate(target_words):\n",
    "                        w2idx = 0  # default [UNK]\n",
    "                        if w in self.target_word2idx:\n",
    "                            w2idx = self.target_word2idx[w]\n",
    "                        if w2idx != 0:\n",
    "                            decoder_input_data_batch[lineIdx, idx, w2idx] = 1\n",
    "                            if idx > 0:\n",
    "                                decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
    "                yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch\n",
    "\n",
    "    def get_weight_file_path(model_dir_path):\n",
    "        return '-weights.h5'\n",
    "\n",
    "    def get_config_file_path(model_dir_path):\n",
    "        return '-config.npy'\n",
    "\n",
    "    def get_architecture_file_path(model_dir_path):\n",
    "        return '-architecture.json'\n",
    "\n",
    "    def fit(self, Xtrain, Ytrain, Xtest, Ytest, epochs=None, batch_size=None, model_dir_path=None):\n",
    "        if epochs is None:\n",
    "            epochs = DEFAULT_EPOCHS\n",
    "        if model_dir_path is None:\n",
    "            model_dir_path = './models'\n",
    "        if batch_size is None:\n",
    "            batch_size = DEFAULT_BATCH_SIZE\n",
    "\n",
    "        self.version += 1\n",
    "        self.config['version'] = self.version\n",
    "        config_file_path = Seq2SeqGloVeSummarizer.get_config_file_path(model_dir_path)\n",
    "        weight_file_path = Seq2SeqGloVeSummarizer.get_weight_file_path(model_dir_path)\n",
    "        checkpoint = ModelCheckpoint(weight_file_path)\n",
    "        np.save(config_file_path, self.config)\n",
    "        architecture_file_path = Seq2SeqGloVeSummarizer.get_architecture_file_path(model_dir_path)\n",
    "        open(architecture_file_path, 'w').write(self.model.to_json())\n",
    "\n",
    "        Ytrain = self.transform_target_encoding(Ytrain)\n",
    "        Ytest = self.transform_target_encoding(Ytest)\n",
    "\n",
    "        Xtrain = self.transform_input_text(Xtrain)\n",
    "        Xtest = self.transform_input_text(Xtest)\n",
    "\n",
    "        train_gen = self.generate_batch(Xtrain, Ytrain, batch_size)\n",
    "        test_gen = self.generate_batch(Xtest, Ytest, batch_size)\n",
    "\n",
    "        train_num_batches = len(Xtrain) // batch_size\n",
    "        test_num_batches = len(Xtest) // batch_size\n",
    "\n",
    "        history = self.model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
    "                                           epochs=epochs,\n",
    "                                           verbose=VERBOSE, validation_data=test_gen, validation_steps=test_num_batches,\n",
    "                                           callbacks=[checkpoint])\n",
    "        self.model.save_weights(weight_file_path)\n",
    "        return history\n",
    "\n",
    "    def summarize(self, input_text):\n",
    "        input_seq = np.zeros(shape=(1, self.max_input_seq_length, GLOVE_EMBEDDING_SIZE))\n",
    "        for idx, word in enumerate(input_text.lower().split(' ')):\n",
    "            if idx >= self.max_input_seq_length:\n",
    "                break\n",
    "            emb = self.unknown_emb  # default [UNK]\n",
    "            if word in self.word2em:\n",
    "                emb = self.word2em[word]\n",
    "            input_seq[0, idx, :] = emb\n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "        target_seq = np.zeros((1, 1, self.num_target_tokens))\n",
    "        target_seq[0, 0, self.target_word2idx['START']] = 1\n",
    "        target_text = ''\n",
    "        target_text_len = 0\n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "            sample_word = self.target_idx2word[sample_token_idx]\n",
    "            target_text_len += 1\n",
    "\n",
    "            if sample_word != 'START' and sample_word != 'END':\n",
    "                target_text += ' ' + sample_word\n",
    "\n",
    "            if sample_word == 'END' or target_text_len >= self.max_target_seq_length:\n",
    "                terminated = True\n",
    "\n",
    "            target_seq = np.zeros((1, 1, self.num_target_tokens))\n",
    "            target_seq[0, 0, sample_token_idx] = 1\n",
    "\n",
    "            states_value = [h, c]\n",
    "        return target_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_UNITS = 100\n",
    "DEFAULT_BATCH_SIZE = 64\n",
    "VERBOSE = 1\n",
    "DEFAULT_EPOCHS = 10\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, Input\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "summarizer = Seq2SeqGloVeSummarizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "summarizer.load_glove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Videet\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer decoder_lstm was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'encoder_lstm/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'encoder_lstm/while/Exit_3:0' shape=(?, 100) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78720,)\n",
      "(19681,)\n",
      "(78720, 92, 100)\n",
      "(19681, 92, 100)\n",
      "Epoch 1/20\n",
      "1230/1230 [==============================] - 447s 363ms/step - loss: 2.1069 - acc: 0.0638 - val_loss: 2.0319 - val_acc: 0.0674\n",
      "Epoch 2/20\n",
      "1230/1230 [==============================] - 457s 372ms/step - loss: 1.9777 - acc: 0.0720 - val_loss: 1.9146 - val_acc: 0.0757\n",
      "Epoch 3/20\n",
      "1230/1230 [==============================] - 460s 374ms/step - loss: 1.8602 - acc: 0.0795 - val_loss: 1.8188 - val_acc: 0.0810\n",
      "Epoch 4/20\n",
      "1230/1230 [==============================] - 462s 376ms/step - loss: 1.7662 - acc: 0.0853 - val_loss: 1.7357 - val_acc: 0.0864\n",
      "Epoch 5/20\n",
      "1230/1230 [==============================] - 457s 372ms/step - loss: 1.6940 - acc: 0.0906 - val_loss: 1.6888 - val_acc: 0.0901\n",
      "Epoch 6/20\n",
      "1230/1230 [==============================] - 467s 380ms/step - loss: 1.6451 - acc: 0.0943 - val_loss: 1.6521 - val_acc: 0.0932\n",
      "Epoch 7/20\n",
      "1230/1230 [==============================] - 482s 392ms/step - loss: 1.6059 - acc: 0.0975 - val_loss: 1.6209 - val_acc: 0.0961\n",
      "Epoch 8/20\n",
      "1230/1230 [==============================] - 465s 378ms/step - loss: 1.5728 - acc: 0.1003 - val_loss: 1.5939 - val_acc: 0.0985\n",
      "Epoch 9/20\n",
      "1230/1230 [==============================] - 480s 390ms/step - loss: 1.5452 - acc: 0.1028 - val_loss: 1.5734 - val_acc: 0.1006\n",
      "Epoch 10/20\n",
      "1230/1230 [==============================] - 474s 386ms/step - loss: 1.5212 - acc: 0.1050 - val_loss: 1.5581 - val_acc: 0.1020\n",
      "Epoch 11/20\n",
      "1230/1230 [==============================] - 542s 440ms/step - loss: 1.5009 - acc: 0.1071 - val_loss: 1.5458 - val_acc: 0.1032\n",
      "Epoch 12/20\n",
      "1230/1230 [==============================] - 570s 464ms/step - loss: 1.4835 - acc: 0.1089 - val_loss: 1.5338 - val_acc: 0.1043\n",
      "Epoch 13/20\n",
      "1230/1230 [==============================] - 562s 457ms/step - loss: 1.4669 - acc: 0.1105 - val_loss: 1.5231 - val_acc: 0.1057\n",
      "Epoch 14/20\n",
      "1230/1230 [==============================] - 542s 441ms/step - loss: 1.4526 - acc: 0.1121 - val_loss: 1.5166 - val_acc: 0.1065\n",
      "Epoch 15/20\n",
      "1230/1230 [==============================] - 479s 390ms/step - loss: 1.4406 - acc: 0.1135 - val_loss: 1.5115 - val_acc: 0.1071\n",
      "Epoch 16/20\n",
      "1230/1230 [==============================] - 479s 389ms/step - loss: 1.4294 - acc: 0.1145 - val_loss: 1.5066 - val_acc: 0.1074\n",
      "Epoch 17/20\n",
      "1230/1230 [==============================] - 478s 389ms/step - loss: 1.4190 - acc: 0.1157 - val_loss: 1.5014 - val_acc: 0.1080\n",
      "Epoch 18/20\n",
      "1230/1230 [==============================] - 478s 388ms/step - loss: 1.4095 - acc: 0.1167 - val_loss: 1.4982 - val_acc: 0.1084\n",
      "Epoch 19/20\n",
      "1230/1230 [==============================] - 479s 389ms/step - loss: 1.4008 - acc: 0.1178 - val_loss: 1.4946 - val_acc: 0.1088\n",
      "Epoch 20/20\n",
      "1230/1230 [==============================] - 483s 393ms/step - loss: 1.3925 - acc: 0.1187 - val_loss: 1.4915 - val_acc: 0.1092\n"
     ]
    }
   ],
   "source": [
    "history = summarizer.fit(Xtrain, Ytrain, Xtest, Ytest, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Generated Headline:  mumbai metro to get its first ever in ipl 2018\n",
      "Original Headline:  upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "1\n",
      "Generated Headline:  pm modi to get its own wedding to get into a report\n",
      "Original Headline:  Delhi techie wins free food from Swiggy for one year on CRED\n",
      "2\n",
      "Generated Headline:  india beat sl to win their first odi series in australia\n",
      "Original Headline:  New Zealand end Rohit Sharma-led India's 12-match winning streak\n",
      "3\n",
      "Generated Headline:  over 100 people in mumbai to be sold at mumbai airport\n",
      "Original Headline:  Aegon life iTerm insurance plan helps customers save tax\n",
      "4\n",
      "Generated Headline:  i am not a good for a film: priyanka on her\n",
      "Original Headline:  Have known Hirani for yrs, what if MeToo claims are not true: Sonam\n",
      "5\n",
      "Generated Headline:  us prez kovind on pak to ban on foreign foreign secy\n",
      "Original Headline:  Rahat Fateh Ali Khan denies getting notice for smuggling currency\n",
      "6\n",
      "Generated Headline:  india beat sl to win their first odi series\n",
      "Original Headline:  India get all out for 92, their lowest ODI total in New Zealand\n",
      "7\n",
      "Generated Headline:  indian man to pay for to get into us for kerala floods\n",
      "Original Headline:  Govt directs Alok Verma to join work 1 day before his retirement\n",
      "8\n",
      "Generated Headline:  i will be a good for my life: aamir khan on his death\n",
      "Original Headline:  Called PM Modi 'sir' 10 times to satisfy his ego: Andhra CM\n",
      "9\n",
      "Generated Headline:  bjp to be in delhi for 2019 polls: pm modi\n",
      "Original Headline:  Cong wins Ramgarh bypoll in Rajasthan, takes total to 100 seats\n",
      "10\n",
      "Generated Headline:  2 people die in mumbai after being hit by indian army\n",
      "Original Headline:  UP cousins fed human excreta for friendship with boys\n",
      "11\n",
      "Generated Headline:  mumbai man gets his own own for a day to be a day\n",
      "Original Headline:  81-yr-old woman conducts physical training in J'khand schools\n",
      "12\n",
      "Generated Headline:  mumbai man to get his wedding to be a pm modi\n",
      "Original Headline:  Ram, Krishna didn't smoke, why should we: Ramdev to sadhus at Kumbh\n",
      "13\n",
      "Generated Headline:  us man who held for most expensive pm modi in india\n",
      "Original Headline:  Pharma exec gave doctor a lap dance to sell medicine in US: Witness\n",
      "14\n",
      "Generated Headline:  i don't want to be a good for my life: priyanka on her\n",
      "Original Headline:   I only cried at my 'bidaai' as I felt peer pressure: Isha Ambani\n",
      "15\n",
      "Generated Headline:  indian banks to pay for to pay for indian billion in us\n",
      "Original Headline:  Louis Vuitton owner to stockpile 4 months of wine, spirits in UK\n",
      "16\n",
      "Generated Headline:  pm modi to get into wedding in delhi\n",
      "Original Headline:  Karan Johar, Tabu turn showstoppers on opening night of LFW\n",
      "17\n",
      "Generated Headline:  pak pm modi to be a man of us open to death\n",
      "Original Headline:  Those on bail will go to jail: PM Modi takes jibe at Rahul\n",
      "18\n",
      "Generated Headline:  congress leader slams for not to meet in india over remark\n",
      "Original Headline:  How long can I tolerate Congress leaders' potshots: K'taka CM\n",
      "19\n",
      "Generated Headline:  will not a woman to be in india: sc on govt\n",
      "Original Headline:  Odisha CM Patnaik controls mining mafia: Union Minister\n",
      "20\n",
      "Generated Headline:  pak pm modi in india as a day for pak president\n",
      "Original Headline:  I think the opposition even dreams about me: PM Modi\n",
      "21\n",
      "Generated Headline:  indian man held in china for 1st indian woman to in india\n",
      "Original Headline:  ISRO unveils Bengaluru centre for manned space mission \n",
      "22\n",
      "Generated Headline:  indian army officer in india over fake news of indian army\n",
      "Original Headline:  12 killed, 170 injured in Saudi Arabia floods\n",
      "23\n",
      "Generated Headline:  man who lost his own wedding in mumbai to be held for 1st time\n",
      "Original Headline:  Isha Ambani features on February cover of Vogue magazine\n",
      "24\n",
      "Generated Headline:  china to pay tax on us to pay for to iran\n",
      "Original Headline:  Indian Oil looking for annual deal to buy crude from US\n",
      "25\n",
      "Generated Headline:  in india win 1st odi to win over ipl 2018\n",
      "Original Headline:  Pacer once took 7 wickets for just 1 run in 32 balls in a Test\n",
      "26\n",
      "Generated Headline:  mumbai man to get a month to pm modi in mumbai\n",
      "Original Headline:  UK zoo offers people to name cockroach after their ex on Valentine's\n",
      "27\n",
      "Generated Headline:  india 1st indian to win their odi series in series\n",
      "Original Headline:  Rohit Sharma becomes 14th Indian cricketer to play 200 ODIs\n",
      "28\n",
      "Generated Headline:  india win 1st to play in ipl 2018 fifa world cup\n",
      "Original Headline:  19-year-old Shubman Gill becomes India's 227th ODI cricketer\n",
      "29\n",
      "Generated Headline:  man who killed in mumbai airport to be sold for a year\n",
      "Original Headline:  2 seat cushions from 'missing plane carrying footballer' found\n",
      "30\n",
      "Generated Headline:  priyanka chopra to be a man for his wedding in us\n",
      "Original Headline:  Italian coach knocks rival down with headbutt, banned for 5 months\n",
      "31\n",
      "Generated Headline:  indian man held for gold worth over crore to win\n",
      "Original Headline:  Cyclists sleep on stadium floor instead of hotel over costly cycles\n",
      "32\n",
      "Generated Headline:  i am not a good for my life: kohli on his own\n",
      "Original Headline:  Brazilian mother narrates football matches to blind son from stands\n",
      "33\n",
      "Generated Headline:  man held for stealing data from india to be paid in india\n",
      "Original Headline:  SBI left account data of millions of users unprotected: Report\n",
      "34\n",
      "Generated Headline:  pak minister to be held for not a indian army\n",
      "Original Headline:  CM Parrikar under pressure from PM after our Goa meet: Rahul\n",
      "35\n",
      "Generated Headline:  man held for stealing fake news of google pm modi in india\n",
      "Original Headline:  Man arrested for cheating Amazon of â¹30 lakh by taking refunds\n",
      "36\n",
      "Generated Headline:  man who arrested for stealing pm modi's us\n",
      "Original Headline:  AgustaWestland scam accused Rajiv Saxena extradited to India\n",
      "37\n",
      "Generated Headline:  us to give pak to pm modi in us\n",
      "Original Headline:  Pakistan holds 'keys to war': Afghanistan\n",
      "38\n",
      "Generated Headline:  man who accused of indian crore in jail for us\n",
      "Original Headline:  Insurance agent 'Lord Voldemort' jailed for threatening clients\n",
      "39\n",
      "Generated Headline:  man held for pm modi to sell for gold on facebook in india\n",
      "Original Headline:  Woman turns Apple AirPods into earrings to avoid losing them\n",
      "40\n",
      "Generated Headline:  cbi probe into a day of the year in court case\n",
      "Original Headline:  Shocked, hurt by ICICI's decision, truth will prevail: Kochhar\n",
      "41\n",
      "Generated Headline:  infosys denies reports of its own body of his own\n",
      "Original Headline:  Fashion brand H&M hires Facebook data scandal whistleblower\n",
      "42\n",
      "Generated Headline:  twitter reacts to us man who hit by indian house in india\n",
      "Original Headline:  Twitter testing news-first timeline feature on Android\n",
      "43\n",
      "Generated Headline:  facebook data from india in india in 3 months\n",
      "Original Headline:  Samsung builds world's first 1TB storage chip for smartphones \n",
      "44\n",
      "Generated Headline:  no one of the world cup in india: us\n",
      "Original Headline:  People with 'negative mindset' quizzing pro-poor schemes: PM\n",
      "45\n",
      "Generated Headline:  i am not a good for a good for india: prez kovind\n",
      "Original Headline:  Rahul is hybrid specimen, has no clue about religion: Hegde\n",
      "46\n",
      "Generated Headline:  india to get in mumbai for world's largest largest plant\n",
      "Original Headline:  Extreme cold to affect 200 million people as polar vortex hits US\n",
      "47\n",
      "Generated Headline:  man held for pm modi in mumbai airport for his own\n",
      "Original Headline:  13 booked for firing air shots at Mahatma Gandhi's effigy\n",
      "48\n",
      "Generated Headline:  man who arrested for gold in mumbai to be held for kerala\n",
      "Original Headline:  Railway police rescues woman with leg stuck in train toilet\n",
      "49\n",
      "Generated Headline:  us to pay pay to pay for to pay for to us\n",
      "Original Headline:  US begins sending back asylum seekers to Mexico\n"
     ]
    }
   ],
   "source": [
    "#summarizer.load_weights(weight_file_path=Seq2SeqSummarizer.get_weight_file_path(model_dir_path='-weights.h5'))\n",
    "\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    x = X[i]\n",
    "    actual_headline = Y[i]\n",
    "    headline = summarizer.summarize(x)\n",
    "    #print('Article: ', x)\n",
    "    print('Generated Headline: ', headline)\n",
    "    print('Original Headline: ', actual_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
